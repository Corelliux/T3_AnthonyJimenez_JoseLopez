{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c43749",
   "metadata": {},
   "source": [
    "# Construccion de triangulo y creación de funciones para data_tarea3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88f5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos y construyendo triángulo...\n",
      "\n",
      "Triángulo acumulado listo para análisis:\n",
      "DevLag                0          1           2           3           4  \\\n",
      "AccidentYear                                                             \n",
      "2005           367000.0  3167000.0   4928000.0   6156000.0   6936000.0   \n",
      "2006          1025000.0  4246000.0   5639000.0   8209000.0  10451000.0   \n",
      "2007          1007000.0  4535000.0   7346000.0   9367000.0  10716000.0   \n",
      "2008          1587000.0  7104000.0  10020000.0  12664000.0  14913000.0   \n",
      "2009          2206000.0  8444000.0  11202400.0  13851900.0  16649600.0   \n",
      "2010          2194000.0  6748000.0  10491000.0  14780900.0         NaN   \n",
      "2011          1165000.0  6145800.0  12758100.0         NaN         NaN   \n",
      "2012          1064600.0  8172400.0         NaN         NaN         NaN   \n",
      "2013          1402400.0        NaN         NaN         NaN         NaN   \n",
      "\n",
      "DevLag                 5           6           7           8  \n",
      "AccidentYear                                                  \n",
      "2005           8225000.0   8951000.0   9754000.0  10272700.0  \n",
      "2006          11386000.0  12860000.0  13460200.0         NaN  \n",
      "2007          11942800.0  13311000.0         NaN         NaN  \n",
      "2008          17207800.0         NaN         NaN         NaN  \n",
      "2009                 NaN         NaN         NaN         NaN  \n",
      "2010                 NaN         NaN         NaN         NaN  \n",
      "2011                 NaN         NaN         NaN         NaN  \n",
      "2012                 NaN         NaN         NaN         NaN  \n",
      "2013                 NaN         NaN         NaN         NaN  \n",
      "\n",
      "--- MÉTODO CHAIN LADDER ---\n",
      "             C_obs   CDF          U_CL       IBNR_CL\n",
      "AY                                                  \n",
      "2005 10,272,700.00  1.00 10,272,700.00          0.00\n",
      "2006 13,460,200.00  1.05 14,175,988.98    715,788.98\n",
      "2007 13,311,000.00  1.12 14,920,750.95  1,609,750.95\n",
      "2008 17,207,800.00  1.25 21,470,043.18  4,262,243.18\n",
      "2009 16,649,600.00  1.41 23,548,285.71  6,898,685.71\n",
      "2010 14,780,900.00  1.68 24,823,468.69 10,042,568.69\n",
      "2011 12,758,100.00  2.20 28,076,344.23 15,318,244.23\n",
      "2012  8,172,400.00  3.40 27,778,524.11 19,606,124.11\n",
      "2013  1,402,400.00 15.55 21,806,464.72 20,404,064.72\n",
      "Total IBNR_CL = 78,857,470.58\n",
      "Total Ultimate_CL = 186,872,570.58\n",
      "\n",
      "--- MÉTODO BORNHUETTER–FERGUSON ---\n",
      "      ELR_i         Prima  p_i  1-p_i       IBNR_BF          U_BF\n",
      "AY                                                               \n",
      "2005   0.80 26,426,000.00 1.00   0.00          0.00 10,272,700.00\n",
      "2006   0.80 34,611,000.00 0.95   0.05  1,398,092.08 14,858,292.08\n",
      "2007   0.80 40,045,000.00 0.89   0.11  3,456,259.12 16,767,259.12\n",
      "2008   0.80 44,158,000.00 0.80   0.20  7,013,013.73 24,220,813.73\n",
      "2009   0.80 48,994,000.00 0.71   0.29 11,482,592.38 28,132,192.38\n",
      "2010   0.80 52,421,000.00 0.60   0.40 16,965,928.49 31,746,828.49\n",
      "2011   0.80 56,597,000.00 0.45   0.55 24,703,121.22 37,461,221.22\n",
      "2012   0.80 59,675,000.00 0.29   0.71 33,694,963.83 41,867,363.83\n",
      "2013   0.80 59,342,000.00 0.06   0.94 44,420,515.63 45,822,915.63\n",
      "Total IBNR_BF = 143,134,486.48\n",
      "Total Ultimate_BF = 251,149,586.48\n",
      "\n",
      "--- MÉTODO CAPE COD ---\n",
      "             C_obs         Prima  p_i  1-p_i       IBNR_CC          U_CC  \\\n",
      "AY                                                                         \n",
      "2005 10,272,700.00 26,426,000.00 1.00   0.00          0.00 10,272,700.00   \n",
      "2006 13,460,200.00 34,611,000.00 0.95   0.05    775,706.30 14,235,906.30   \n",
      "2007 13,311,000.00 40,045,000.00 0.89   0.11  1,917,643.34 15,228,643.34   \n",
      "2008 17,207,800.00 44,158,000.00 0.80   0.20  3,891,044.80 21,098,844.80   \n",
      "2009 16,649,600.00 48,994,000.00 0.71   0.29  6,370,910.31 23,020,510.31   \n",
      "2010 14,780,900.00 52,421,000.00 0.60   0.40  9,413,240.94 24,194,140.94   \n",
      "2011 12,758,100.00 56,597,000.00 0.45   0.55 13,706,083.47 26,464,183.47   \n",
      "2012  8,172,400.00 59,675,000.00 0.29   0.71 18,695,045.96 26,867,445.96   \n",
      "2013  1,402,400.00 59,342,000.00 0.06   0.94 24,645,925.89 26,048,325.89   \n",
      "\n",
      "      theta_hat  \n",
      "AY               \n",
      "2005       0.44  \n",
      "2006       0.44  \n",
      "2007       0.44  \n",
      "2008       0.44  \n",
      "2009       0.44  \n",
      "2010       0.44  \n",
      "2011       0.44  \n",
      "2012       0.44  \n",
      "2013       0.44  \n",
      "Theta_hat = 0.443865643\n",
      "Total IBNR_CC = 79,415,601.01\n",
      "Total Ultimate_CC = 187,430,701.01\n",
      "\n",
      "=== RESUMEN FINAL ===\n",
      "                 Método     IBNR Total  Ultimate Total\n",
      "0          Chain Ladder  78,857,470.58  186,872,570.58\n",
      "1  Bornhuetter–Ferguson 143,134,486.48  251,149,586.48\n",
      "2              Cape Cod  79,415,601.01  187,430,701.01\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =======================================\n",
    "# DATOS DE ENTRADA DESDE CHUNK 2\n",
    "# =======================================\n",
    "INPUT_PATH = \"data_tarea3.xlsx\"\n",
    "RATIO_ELR_GLOBAL = 0.8  # ELR único (global)\n",
    "print(\"Cargando datos y construyendo triángulo...\")\n",
    "\n",
    "# --- Funciones necesarias del Chunk 2 para generar el triángulo ---\n",
    "def load_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo: {path}\")\n",
    "    df = pd.read_excel(path)\n",
    "    df = df.rename(columns=lambda c: str(c).strip())\n",
    "    for c in df.columns:\n",
    "        lc = str(c).lower()\n",
    "        if 'evento' in lc or 'ocur' in lc:\n",
    "            df = df.rename(columns={c: 'Fecha Evento'})\n",
    "        if 'notifi' in lc or 'f_pago' in lc or 'not' in lc:\n",
    "            df = df.rename(columns={c: 'Fecha Notifi'})\n",
    "        if 'monto' in lc or 'siniest' in lc or 'pago' in lc:\n",
    "            df = df.rename(columns={c: 'Monto Siniestro'})\n",
    "    if not set(['Fecha Evento', 'Fecha Notifi', 'Monto Siniestro']).issubset(df.columns):\n",
    "        raise ValueError(f\"Columnas esperadas no encontradas. Columnas actuales: {df.columns.tolist()}\")\n",
    "    df['Fecha Evento'] = pd.to_datetime(df['Fecha Evento'], errors='coerce')\n",
    "    df['Fecha Notifi'] = pd.to_datetime(df['Fecha Notifi'], errors='coerce')\n",
    "    df = df.dropna(subset=['Fecha Evento', 'Fecha Notifi'])\n",
    "    df['Monto Siniestro'] = pd.to_numeric(df['Monto Siniestro'], errors='coerce').fillna(0.0)\n",
    "    return df\n",
    "\n",
    "def build_triangle_accumulated(df):\n",
    "    df = df.copy()\n",
    "    df['AccidentYear'] = df['Fecha Evento'].dt.year\n",
    "    df['DevLag'] = (df['Fecha Notifi'].dt.year - df['AccidentYear']).astype(int)\n",
    "    df = df[df['DevLag'] >= 0]\n",
    "    tri_inc = df.pivot_table(index='AccidentYear', columns='DevLag',\n",
    "                             values='Monto Siniestro', aggfunc='sum', fill_value=0.0)\n",
    "    tri_inc = tri_inc.sort_index(axis=0).sort_index(axis=1)\n",
    "    maxlag = int(tri_inc.columns.max())\n",
    "    tri_inc = tri_inc.reindex(columns=range(maxlag+1), fill_value=0.0)\n",
    "    triangle_acum = tri_inc.cumsum(axis=1)\n",
    "    latest_year = triangle_acum.index.max()\n",
    "    for ay in triangle_acum.index:\n",
    "        years_available = latest_year - ay\n",
    "        if years_available + 1 < triangle_acum.shape[1]:\n",
    "            triangle_acum.loc[ay, years_available+1:] = np.nan\n",
    "    return triangle_acum\n",
    "\n",
    "# --- Cargar datos y construir triángulo ---\n",
    "df = load_data(INPUT_PATH)\n",
    "triangle = build_triangle_accumulated(df)\n",
    "\n",
    "# --- Definir primas desde el chunk 2 ---\n",
    "primas = pd.Series({\n",
    "    2005: 26426000,\n",
    "    2006: 34611000,\n",
    "    2007: 40045000,\n",
    "    2008: 44158000,\n",
    "    2009: 48994000,\n",
    "    2010: 52421000,\n",
    "    2011: 56597000,\n",
    "    2012: 59675000,\n",
    "    2013: 59342000\n",
    "})\n",
    "\n",
    "# --- Crear serie de ELR (constante 0.8 para todos los años) ---\n",
    "elr = pd.Series(RATIO_ELR_GLOBAL, index=triangle.index)\n",
    "\n",
    "print(\"\\nTriángulo acumulado listo para análisis:\")\n",
    "print(triangle)\n",
    "\n",
    "# =======================================\n",
    "# FUNCIONES ORIGINALES (NO MODIFICADAS)\n",
    "# =======================================\n",
    "def calc_linkratios_and_cdf(tri):\n",
    "    lags = list(tri.columns)\n",
    "    f = []\n",
    "    for k in range(len(lags)-1):\n",
    "        col_k = lags[k]\n",
    "        col_k1 = lags[k+1]\n",
    "        mask = tri[[col_k, col_k1]].notna().all(axis=1)\n",
    "        num = tri.loc[mask, col_k1].sum()\n",
    "        den = tri.loc[mask, col_k].sum()\n",
    "        if den == 0:\n",
    "            raise ZeroDivisionError(f\"Denominador cero para f_{k} (lag {col_k}). Revisa el triángulo y los NaN.\")\n",
    "        fk = num/den\n",
    "        f.append(fk)\n",
    "    f = np.array(f, dtype=float)\n",
    "    CDF = np.ones(len(f)+1, dtype=float)\n",
    "    for i in range(len(f)-1, -1, -1):\n",
    "        CDF[i] = CDF[i+1] * f[i]\n",
    "    cdf_series = pd.Series(CDF, index=lags)\n",
    "    if (cdf_series < 1 - 1e-12).any():\n",
    "        print(\"WARNING: alguna CDF < 1. Revisa link ratios. Valores:\\n\", cdf_series)\n",
    "    return f, cdf_series\n",
    "\n",
    "def metodo_chain_ladder(tri):\n",
    "    f, CDF = calc_linkratios_and_cdf(tri)\n",
    "    rows = []\n",
    "    for ay in tri.index:\n",
    "        row = tri.loc[ay]\n",
    "        if row.notna().sum() == 0:\n",
    "            raise ValueError(f\"AY {ay} sin observaciones.\")\n",
    "        edad = int(row.last_valid_index())\n",
    "        C_obs = float(row.loc[edad])\n",
    "        cdf_val = float(CDF.loc[edad])\n",
    "        U_CL = C_obs * cdf_val\n",
    "        IBNR_CL = U_CL - C_obs\n",
    "        rows.append([ay, C_obs, cdf_val, U_CL, IBNR_CL])\n",
    "    df = pd.DataFrame(rows, columns=[\"AY\",\"C_obs\",\"CDF\",\"U_CL\",\"IBNR_CL\"]).set_index(\"AY\")\n",
    "    return df, CDF\n",
    "\n",
    "def metodo_bornhuetter_ferguson(tri, primas, elr, CDF):\n",
    "    rows = []\n",
    "    for ay in tri.index:\n",
    "        row = tri.loc[ay]\n",
    "        edad = int(row.last_valid_index())\n",
    "        cdf_val = float(CDF.loc[edad])\n",
    "        p_i = 1.0 / cdf_val\n",
    "        uno_menos_p = 1.0 - p_i\n",
    "        IBNR_BF = float(elr.loc[ay]) * float(primas.loc[ay]) * uno_menos_p\n",
    "        C_obs = float(row.loc[edad])\n",
    "        U_BF = C_obs + IBNR_BF  # CALCULAR ULTIMATE\n",
    "        rows.append([ay, float(elr.loc[ay]), float(primas.loc[ay]), p_i, uno_menos_p, IBNR_BF, U_BF])\n",
    "    df = pd.DataFrame(rows, columns=[\"AY\",\"ELR_i\",\"Prima\",\"p_i\",\"1-p_i\",\"IBNR_BF\",\"U_BF\"]).set_index(\"AY\")\n",
    "    return df\n",
    "\n",
    "def metodo_cape_cod(tri, primas, CDF):\n",
    "    rows = []\n",
    "    num_sum = 0.0\n",
    "    den_sum = 0.0\n",
    "    for ay in tri.index:\n",
    "        row = tri.loc[ay]\n",
    "        edad = int(row.last_valid_index())\n",
    "        C_obs = float(row.loc[edad])\n",
    "        cdf_val = float(CDF.loc[edad])\n",
    "        p_i = 1.0 / cdf_val\n",
    "        uno_menos_p = 1.0 - p_i\n",
    "        num_sum += C_obs\n",
    "        den_sum += float(primas.loc[ay]) * p_i\n",
    "        rows.append([ay, C_obs, float(primas.loc[ay]), p_i, uno_menos_p])\n",
    "    theta_hat = num_sum / den_sum\n",
    "    rows2 = []\n",
    "    for r in rows:\n",
    "        ay, C_obs, prima, p_i, uno_menos_p = r\n",
    "        IBNR_CC = theta_hat * prima * uno_menos_p\n",
    "        U_CC = C_obs + IBNR_CC  # CALCULAR ULTIMATE\n",
    "        rows2.append([ay, C_obs, prima, p_i, uno_menos_p, IBNR_CC, U_CC])\n",
    "    df = pd.DataFrame(rows2, columns=[\"AY\",\"C_obs\",\"Prima\",\"p_i\",\"1-p_i\",\"IBNR_CC\",\"U_CC\"]).set_index(\"AY\")\n",
    "    df[\"theta_hat\"] = theta_hat\n",
    "    return df, theta_hat\n",
    "\n",
    "# =======================================\n",
    "# EJECUCIÓN DE LOS MÉTODOS\n",
    "# =======================================\n",
    "df_cl, CDF = metodo_chain_ladder(triangle)\n",
    "df_bf = metodo_bornhuetter_ferguson(triangle, primas, elr, CDF)\n",
    "df_cc, theta_hat = metodo_cape_cod(triangle, primas, CDF)\n",
    "\n",
    "# =======================================\n",
    "# RESUMEN FINAL (CORREGIDO)\n",
    "# =======================================\n",
    "resumen = pd.DataFrame({\n",
    "    \"Método\": [\"Chain Ladder\", \"Bornhuetter–Ferguson\", \"Cape Cod\"],\n",
    "    \"IBNR Total\": [df_cl[\"IBNR_CL\"].sum(), df_bf[\"IBNR_BF\"].sum(), df_cc[\"IBNR_CC\"].sum()],\n",
    "    \"Ultimate Total\": [df_cl[\"U_CL\"].sum(), df_bf[\"U_BF\"].sum(), df_cc[\"U_CC\"].sum()]\n",
    "})\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "print(\"\\n--- MÉTODO CHAIN LADDER ---\")\n",
    "print(df_cl)\n",
    "print(f\"Total IBNR_CL = {df_cl['IBNR_CL'].sum():,.2f}\")\n",
    "print(f\"Total Ultimate_CL = {df_cl['U_CL'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n--- MÉTODO BORNHUETTER–FERGUSON ---\")\n",
    "print(df_bf)\n",
    "print(f\"Total IBNR_BF = {df_bf['IBNR_BF'].sum():,.2f}\")\n",
    "print(f\"Total Ultimate_BF = {df_bf['U_BF'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n--- MÉTODO CAPE COD ---\")\n",
    "print(df_cc)\n",
    "print(f\"Theta_hat = {theta_hat:.9f}\")\n",
    "print(f\"Total IBNR_CC = {df_cc['IBNR_CC'].sum():,.2f}\")\n",
    "print(f\"Total Ultimate_CC = {df_cc['U_CC'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n=== RESUMEN FINAL ===\")\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd83b60",
   "metadata": {},
   "source": [
    "Al comparar los resultados obtenidos mediante los tres métodos de estimación de reservas, se observa que el Chain Ladder arroja un IBNR total de aproximadamente 78,86 millones, reflejando directamente los patrones históricos de desarrollo de siniestros. Este método es adecuado cuando la experiencia pasada es estable, pero puede llegar a subestimar la reserva en los años recientes donde la maduración aún es parcial. Por su parte, el Bornhuetter–Ferguson genera la reserva más alta, alrededor de 143,13 millones, al combinar la información histórica con la expectativa a priori basada en el ELR (que en este caso fue ELR=0.8) y las primas. Esto lo hace más prudente y conservador, especialmente útil en situaciones de alta incertidumbre o cambios recientes en la siniestralidad. El Cape Cod, con un IBNR de aproximadamente 79,42 millones, estima el ELR internamente a partir de los datos observados, ofreciendo un equilibrio entre la experiencia histórica y la expectativa teórica. Considerando que el triángulo muestra patrones consistentes y los años recientes presentan desarrollo parcial, se recomienda adoptar el método Cape Cod como base para la reserva técnica, ya que proporciona un valor razonable, evita sobre-reservar como puede ser que se este haciendo en BF dado al alto valor del ratio de siniestralidad dado, además permite justificar la consistencia entre los datos observados y la exposición futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fac076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MÉTODO CHAIN LADDER ---\n",
      "       C_obs  CDF      U_CL   IBNR_CL\n",
      "AY                                   \n",
      "0  44,490.00 1.00 44,490.00      0.00\n",
      "1  42,114.00 1.01 42,502.82    388.82\n",
      "2  37,257.00 1.16 43,346.91  6,089.91\n",
      "3  25,266.00 1.68 42,392.88 17,126.88\n",
      "4   9,072.00 4.68 42,420.96 33,348.96\n",
      "Total IBNR_CL = 56,954.56\n",
      "\n",
      "--- MÉTODO BORNHUETTER–FERGUSON ---\n",
      "    ELR_i     Prima  p_i  1-p_i   IBNR_BF      U_BF\n",
      "AY                                                 \n",
      "0    0.84 52,600.00 1.00   0.00      0.00 44,490.00\n",
      "1    0.82 54,000.00 0.99   0.01    405.08 42,519.08\n",
      "2    0.80 55,520.00 0.86   0.14  6,240.11 43,497.11\n",
      "3    0.80 57,500.00 0.60   0.40 18,584.17 43,850.17\n",
      "4    0.80 59,850.00 0.21   0.79 37,640.55 46,712.55\n",
      "Total IBNR_BF = 62,869.90\n",
      "\n",
      "--- MÉTODO CAPE COD ---\n",
      "       C_obs     Prima  p_i  1-p_i   IBNR_CC      U_CC  theta_hat\n",
      "AY                                                               \n",
      "0  44,490.00 52,600.00 1.00   0.00      0.00 44,490.00       0.79\n",
      "1  42,114.00 54,000.00 0.99   0.01    389.01 42,503.01       0.79\n",
      "2  37,257.00 55,520.00 0.86   0.14  6,142.38 43,399.38       0.79\n",
      "3  25,266.00 57,500.00 0.60   0.40 18,293.12 43,559.12       0.79\n",
      "4   9,072.00 59,850.00 0.21   0.79 37,051.06 46,123.06       0.79\n",
      "Theta_hat = 0.787471171\n",
      "Total IBNR_CC = 61,875.57\n",
      "\n",
      "=== RESUMEN FINAL ===\n",
      "                 Método  IBNR Total\n",
      "0          Chain Ladder   56,954.56\n",
      "1  Bornhuetter–Ferguson   62,869.90\n",
      "2              Cape Cod   61,875.57\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# Datos del ejercicio (triángulo y primas / ELR)\n",
    "# --------------------------\n",
    "triangle_data = {\n",
    "    0: [9502, 8138, 9802, 9498, 9072],\n",
    "    1: [25827, 26292, 25563, 25266, np.nan],\n",
    "    2: [37275, 37496, 37257, np.nan, np.nan],\n",
    "    3: [44083, 42114, np.nan, np.nan, np.nan],\n",
    "    4: [44490, np.nan, np.nan, np.nan, np.nan]\n",
    "}\n",
    "triangle = pd.DataFrame(triangle_data, index=[0, 1, 2, 3, 4])\n",
    "triangle.index.name = \"AY\"\n",
    "triangle.columns.name = \"DevLag\"\n",
    "\n",
    "primas = pd.Series([52600, 54000, 55520, 57500, 59850], index=[0, 1, 2, 3, 4])\n",
    "elr = pd.Series([0.84, 0.82, 0.80, 0.80, 0.80], index=[0, 1, 2, 3, 4])\n",
    "\n",
    "# --------------------------\n",
    "# Probar los métodos con la información original\n",
    "# --------------------------\n",
    "df_cl, CDF = metodo_chain_ladder(triangle)\n",
    "df_bf = metodo_bornhuetter_ferguson(triangle, primas, elr, CDF)\n",
    "df_cc, theta_hat = metodo_cape_cod(triangle, primas, CDF)\n",
    "\n",
    "# --------------------------\n",
    "# Resumen de resultados\n",
    "# --------------------------\n",
    "resumen = pd.DataFrame({\n",
    "    \"Método\": [\"Chain Ladder\", \"Bornhuetter–Ferguson\", \"Cape Cod\"],\n",
    "    \"IBNR Total\": [df_cl[\"IBNR_CL\"].sum(), df_bf[\"IBNR_BF\"].sum(), df_cc[\"IBNR_CC\"].sum()]\n",
    "})\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "print(\"\\n--- MÉTODO CHAIN LADDER ---\")\n",
    "print(df_cl)\n",
    "print(f\"Total IBNR_CL = {df_cl['IBNR_CL'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n--- MÉTODO BORNHUETTER–FERGUSON ---\")\n",
    "print(df_bf)\n",
    "print(f\"Total IBNR_BF = {df_bf['IBNR_BF'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n--- MÉTODO CAPE COD ---\")\n",
    "print(df_cc)\n",
    "print(f\"Theta_hat = {theta_hat:.9f}\")\n",
    "print(f\"Total IBNR_CC = {df_cc['IBNR_CC'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n=== RESUMEN FINAL ===\")\n",
    "print(resumen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd781c26",
   "metadata": {},
   "source": [
    "## BORRADOR: Prueba de que estén bien calculados usando Ej 1 Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d0dc12-0b8b-45e0-bddc-8c28219e4e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AY (todos hasta el corte): [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "AY (últimos 5): [2020, 2021, 2022, 2023, 2024]\n",
      "\n",
      "Pagados (incremental):\n",
      "                   0              1            2             3    4\n",
      "2020 127,048,900.88 134,385,019.33         0.00    170,247.00 0.00\n",
      "2021 139,459,172.17 256,277,558.94 1,318,728.53 15,120,362.39 0.00\n",
      "2022 930,540,084.90  97,437,232.42   288,635.40          0.00 0.00\n",
      "2023 192,285,461.87  77,809,419.18         0.00          0.00 0.00\n",
      "2024 164,806,598.66           0.00         0.00          0.00 0.00\n",
      "\n",
      "Pagados (acumulado):\n",
      "                   0                1                2              3              4\n",
      "2020 127,048,900.88   261,433,920.21   261,433,920.21 261,604,167.21 261,604,167.21\n",
      "2021 139,459,172.17   395,736,731.11   397,055,459.64 412,175,822.04            NaN\n",
      "2022 930,540,084.90 1,027,977,317.32 1,028,265,952.72            NaN            NaN\n",
      "2023 192,285,461.87   270,094,881.05              NaN            NaN            NaN\n",
      "2024 164,806,598.66              NaN              NaN            NaN            NaN\n",
      "\n",
      "Reservas:\n",
      "                   0             1            2    3    4\n",
      "2020  89,214,145.46  3,875,941.12 3,883,344.75 0.00 0.00\n",
      "2021 168,195,980.20 40,723,619.75 6,126,702.00 0.00  NaN\n",
      "2022  60,742,660.50  4,053,497.88   928,747.91  NaN  NaN\n",
      "2023  79,914,531.72 15,714,987.48          NaN  NaN  NaN\n",
      "2024 956,208,813.75           NaN          NaN  NaN  NaN\n",
      "\n",
      "Incurridos:\n",
      "                     0                1                2              3              4\n",
      "2020   216,263,046.34   265,309,861.33   265,317,264.96 261,604,167.21 261,604,167.21\n",
      "2021   307,655,152.37   436,460,350.86   403,182,161.64 412,175,822.04            NaN\n",
      "2022   991,282,745.40 1,032,030,815.20 1,029,194,700.63            NaN            NaN\n",
      "2023   272,199,993.59   285,809,868.53              NaN            NaN            NaN\n",
      "2024 1,121,015,412.41              NaN              NaN            NaN            NaN\n",
      "\n",
      "Factores acumulados (CDF):\n",
      "        CDF\n",
      "Dev 0 1.12\n",
      "Dev 1 0.99\n",
      "Dev 2 1.01\n",
      "Dev 3 0.99\n",
      "Dev 4 1.00\n",
      "\n",
      "Parámetros de Mack (f, sigma^2, S, n_pairs):\n",
      "             f        sigma2                S  n_pairs\n",
      "Dev 0->1 1.13 12,412,652.29 1,787,400,937.70        4\n",
      "Dev 1->2 0.98    604,719.64 1,846,541,723.08        4\n",
      "Dev 2->3 1.02  1,708,526.18   812,292,305.33        4\n",
      "Dev 3->4 0.99    775,918.26   455,813,620.40        4\n",
      "\n",
      "Resultados Mack por AY:\n",
      "       k_obs            C_obs  CDF    Ultimate_Mack      IBNR_Mack        SE_Mack\n",
      "2020      4   261,604,167.21 1.00   261,604,167.21           0.00           0.00\n",
      "2021      3   412,175,822.04 0.99   406,771,783.43  -5,404,038.61  17,005,791.48\n",
      "2022      2 1,029,194,700.63 1.01 1,040,186,311.74  10,991,611.10  64,179,777.56\n",
      "2023      1   285,809,868.53 0.99   282,598,308.50  -3,211,560.03  18,187,340.46\n",
      "2024      0 1,121,015,412.41 1.12 1,252,418,993.00 131,403,580.59 123,384,772.81\n",
      "\n",
      "Totales:\n",
      "    IBNR Total Mack  Ultimate Total Mack  SE Total (aprox)\n",
      "0   133,779,593.06     3,243,579,563.87    141,289,852.09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==========================\n",
    "# PARÁMETROS\n",
    "# ==========================\n",
    "INPUT_PATH = \"Data_Ejercicio2.xlsx\"\n",
    "CUTOFF = pd.Timestamp(\"2024-06-30\")   # corte a junio 2024\n",
    "N_DEV = 5                             \n",
    "\n",
    "# ==========================\n",
    "# Funciones para manejo de fechas\n",
    "# ==========================\n",
    "def ay_end_year(dt: pd.Timestamp) -> int:\n",
    "    return int(dt.year + 1) if dt.month >= 7 else int(dt.year)\n",
    "\n",
    "def val_year_from_date(dt: pd.Timestamp) -> int:\n",
    "    return int(dt.year) if dt.month <= 6 else int(dt.year + 1)\n",
    "\n",
    "def year_window(val_year: int):\n",
    "    start = pd.Timestamp(val_year - 1, 7, 1)\n",
    "    end = pd.Timestamp(val_year, 6, 30, 23, 59, 59)\n",
    "    return start, end\n",
    "\n",
    "def to_datetime_clean(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def to_numeric_clean(s):\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "    return pd.to_numeric(\n",
    "        s.astype(str)\n",
    "         .str.replace(r\"[^\\d\\-\\.,]\", \"\", regex=True)\n",
    "         .str.replace(\".\", \"\", regex=False)\n",
    "         .str.replace(\",\", \".\", regex=False),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "# ==========================\n",
    "# Funciones para manejo de columnas\n",
    "# ==========================\n",
    "def detect_columns_strict(df: pd.DataFrame):\n",
    "    def _has(s, *keys):\n",
    "        s = str(s).lower()\n",
    "        return any(k in s for k in keys)\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    mapping = {\"fecha_evento\": None, \"fecha_mov\": None, \"id_siniestro\": None,\n",
    "               \"monto_pagado\": None, \"monto_reserva\": None}\n",
    "    date_candidates = [c for c in cols if _has(c, \"fec\", \"fecha\", \"date\")]\n",
    "    def is_datetime_col(c):\n",
    "        s = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "        return s.notna().mean() >= 0.7\n",
    "    parsed = [c for c in date_candidates if is_datetime_col(c)]\n",
    "\n",
    "    for c in parsed:\n",
    "        if mapping[\"fecha_evento\"] is None and _has(c, \"ocurr\", \"ocur\", \"evento\", \"accident\"):\n",
    "            mapping[\"fecha_evento\"] = c\n",
    "    if mapping[\"fecha_evento\"] is None and parsed:\n",
    "        mapping[\"fecha_evento\"] = parsed[0]\n",
    "\n",
    "    for c in parsed:\n",
    "        if mapping[\"fecha_mov\"] is None and _has(c, \"mov\", \"transac\", \"notif\", \"notifi\", \"pago\", \"res\"):\n",
    "            mapping[\"fecha_mov\"] = c\n",
    "    if mapping[\"fecha_mov\"] is None:\n",
    "        if len(parsed) >= 2: mapping[\"fecha_mov\"] = parsed[1]\n",
    "        elif parsed:        mapping[\"fecha_mov\"] = parsed[0]\n",
    "\n",
    "    for c in cols:\n",
    "        if mapping[\"id_siniestro\"] is None and _has(c, \"sini\", \"claim\", \"exped\", \"numero\", \"n°\", \"nro\", \"id\"):\n",
    "            mapping[\"id_siniestro\"] = c\n",
    "        if mapping[\"monto_pagado\"] is None and _has(c, \"pag\") and not _has(c, \"fec\", \"fecha\", \"date\"):\n",
    "            mapping[\"monto_pagado\"] = c\n",
    "        if mapping[\"monto_reserva\"] is None and _has(c, \"reserv\") and not _has(c, \"fec\", \"fecha\", \"date\"):\n",
    "            mapping[\"monto_reserva\"] = c\n",
    "\n",
    "    if mapping[\"fecha_evento\"] is None or mapping[\"fecha_mov\"] is None:\n",
    "        raise ValueError(\"Faltan columnas mínimas para fechas. Columnas: \" + str(list(df.columns)))\n",
    "    return mapping\n",
    "\n",
    "# ==========================\n",
    "# TRIANGULOS\n",
    "# ==========================\n",
    "def build_paid_triangle(df, col_event, col_move, col_paid, ay_list_full, n_dev):\n",
    "    paid = to_numeric_clean(df[col_paid]).fillna(0.0) if col_paid is not None else pd.Series(0.0, index=df.index)\n",
    "    tmp = pd.DataFrame({\n",
    "        \"ay\": df[col_event].apply(ay_end_year),\n",
    "        \"vy\": df[col_move].apply(val_year_from_date),\n",
    "        \"paid\": paid\n",
    "    }).dropna(subset=[\"ay\", \"vy\"])\n",
    "\n",
    "    tmp = tmp[(tmp[\"vy\"] <= CUTOFF.year) & (tmp[\"paid\"] != 0.0) & (tmp[\"ay\"].isin(ay_list_full))]\n",
    "    g = tmp.groupby([\"ay\", \"vy\"], as_index=False)[\"paid\"].sum()\n",
    "    g[\"dev\"] = g[\"vy\"] - g[\"ay\"]\n",
    "    g = g[(g[\"dev\"] >= 0) & (g[\"dev\"] < n_dev)]\n",
    "\n",
    "    inc = g.pivot_table(index=\"ay\", columns=\"dev\", values=\"paid\", aggfunc=\"sum\", fill_value=0.0)\n",
    "    inc = inc.reindex(index=ay_list_full, columns=range(n_dev), fill_value=0.0)\n",
    "    cum = inc.cumsum(axis=1)  # <-- acumulado desde dev 0\n",
    "    for ay in cum.index:\n",
    "        last_vy = min(CUTOFF.year, ay + n_dev - 1)\n",
    "        max_dev_obs = last_vy - ay\n",
    "        if max_dev_obs + 1 < n_dev:\n",
    "            cum.loc[ay, list(range(max_dev_obs + 1, n_dev))] = np.nan\n",
    "    return inc, cum\n",
    "\n",
    "def build_reserve_triangle(df, col_event, col_move, col_reserve, col_id, ay_list_full, n_dev):\n",
    "    if col_reserve is None:\n",
    "        res = pd.DataFrame(0.0, index=ay_list_full, columns=range(n_dev))\n",
    "        for ay in ay_list_full:\n",
    "            last_vy = min(CUTOFF.year, ay + n_dev - 1)\n",
    "            max_dev_obs = last_vy - ay\n",
    "            if max_dev_obs + 1 < n_dev:\n",
    "                res.loc[ay, list(range(max_dev_obs + 1, n_dev))] = np.nan\n",
    "        return res\n",
    "\n",
    "    keep_cols = [col_event, col_move, col_reserve] + ([col_id] if col_id else [])\n",
    "    df2 = df[keep_cols].copy()\n",
    "    df2[col_event] = to_datetime_clean(df2[col_event])\n",
    "    df2[col_move] = to_datetime_clean(df2[col_move])\n",
    "    df2[col_reserve] = to_numeric_clean(df2[col_reserve]).fillna(0.0)\n",
    "    df2[\"ay\"] = df2[col_event].apply(ay_end_year)\n",
    "    df2 = df2[df2[\"ay\"].isin(ay_list_full)]\n",
    "    df2 = df2[df2[col_move] <= CUTOFF]\n",
    "\n",
    "    result = pd.DataFrame(index=ay_list_full, columns=range(n_dev), dtype=float)\n",
    "    for ay in ay_list_full:\n",
    "        for dev in range(n_dev):\n",
    "            vy = ay + dev\n",
    "            if vy > CUTOFF.year:\n",
    "                result.loc[ay, dev] = np.nan\n",
    "                continue\n",
    "            _, end = year_window(vy)\n",
    "\n",
    "            if col_id:\n",
    "                sub = df2[(df2[\"ay\"] == ay) & (df2[col_move] <= end)]\n",
    "                if sub.empty:\n",
    "                    result.loc[ay, dev] = 0.0\n",
    "                else:\n",
    "                    sub = sub.sort_values([col_id, col_move])\n",
    "                    last_by_claim = sub.groupby(col_id, as_index=False).tail(1)\n",
    "                    result.loc[ay, dev] = float(last_by_claim[col_reserve].sum())\n",
    "            else:\n",
    "                sub = df2[(df2[\"ay\"] == ay) &\n",
    "                          (df2[col_move].dt.month == 6) &\n",
    "                          (df2[col_move].dt.year == vy)]\n",
    "                result.loc[ay, dev] = float(sub[col_reserve].sum()) if not sub.empty else 0.0\n",
    "    return result\n",
    "\n",
    "# ==========================\n",
    "# MACK\n",
    "# ==========================\n",
    "def mack_chain_ladder(tri_cum: pd.DataFrame):\n",
    "    tri = tri_cum.copy()\n",
    "    n_dev = tri.shape[1]\n",
    "    f, s2, S, n_pairs = [], [], [], []\n",
    "    for k in range(n_dev - 1):\n",
    "        col_k = tri.iloc[:, k]\n",
    "        col_k1 = tri.iloc[:, k + 1]\n",
    "        mask = col_k.notna() & col_k1.notna() & (col_k > 0)\n",
    "        den = col_k[mask].sum()\n",
    "        num = col_k1[mask].sum()\n",
    "        if den == 0 or mask.sum() == 0:\n",
    "            f_k = np.nan; s2_k = np.nan; S_k = 0.0; n_pairs.append(0)\n",
    "        else:\n",
    "            f_k = float(num / den)\n",
    "            ratios = (col_k1[mask] / col_k[mask]).values\n",
    "            vols = col_k[mask].values\n",
    "            s2_k = float(np.sum(vols * (ratios - f_k) ** 2) / (mask.sum() - 1)) if mask.sum() >= 2 else 0.0\n",
    "            S_k = float(den); n_pairs.append(int(mask.sum()))\n",
    "        f.append(f_k); s2.append(s2_k); S.append(S_k)\n",
    "\n",
    "    f = np.array(f, dtype=float); s2 = np.array(s2, dtype=float); S = np.array(S, dtype=float)\n",
    "\n",
    "    F = np.ones(n_dev, dtype=float)\n",
    "    for k in range(n_dev - 2, -1, -1):\n",
    "        F[k] = F[k + 1] * (f[k] if not np.isnan(f[k]) else 1.0)\n",
    "\n",
    "    rows = []\n",
    "    for ay in tri.index:\n",
    "        row = tri.loc[ay]\n",
    "        if row.notna().sum() == 0:\n",
    "            continue\n",
    "        k_i = int(row.last_valid_index()) if isinstance(row.last_valid_index(), int) else int(row.index[row.notna()].max())\n",
    "        C_obs = float(row.iloc[k_i])\n",
    "        U_hat = C_obs * F[k_i]\n",
    "        IBNR = U_hat - C_obs\n",
    "\n",
    "        mse = 0.0; C_hat_k = C_obs\n",
    "        for kk in range(k_i, n_dev - 1):\n",
    "            add = 0.0 if (S[kk] == 0 or np.isnan(s2[kk])) else (C_hat_k ** 2) * (s2[kk] / S[kk])\n",
    "            mse += add\n",
    "            C_hat_k = C_hat_k * (f[kk] if not np.isnan(f[kk]) else 1.0)\n",
    "        se = math.sqrt(max(mse, 0.0))\n",
    "        rows.append([ay, k_i, C_obs, F[k_i], U_hat, IBNR, se])\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\"AY\", \"k_obs\", \"C_obs\", \"CDF\", \"Ultimate_Mack\", \"IBNR_Mack\", \"SE_Mack\"]).set_index(\"AY\")\n",
    "    params = pd.DataFrame({\"f\": f, \"sigma2\": s2, \"S\": S, \"n_pairs\": [int(x) for x in n_pairs]},\n",
    "                          index=[f\"Dev {k}->{k+1}\" for k in range(n_dev - 1)])\n",
    "    cdf_df = pd.DataFrame({\"CDF\": F}, index=[f\"Dev {k}\" for k in range(n_dev)])\n",
    "    return out, cdf_df, params\n",
    "\n",
    "# ==========================\n",
    "# PIPELINE\n",
    "# ==========================\n",
    "def run_pipeline(input_path=INPUT_PATH, cutoff=CUTOFF, n_dev=N_DEV, keep_last5=True):\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo: {input_path}\")\n",
    "\n",
    "    df_raw = pd.read_excel(input_path).rename(columns=lambda c: str(c).strip())\n",
    "    mapping = detect_columns_strict(df_raw)\n",
    "\n",
    "    # limpieza\n",
    "    df = df_raw.copy()\n",
    "    df[mapping[\"fecha_evento\"]] = to_datetime_clean(df[mapping[\"fecha_evento\"]])\n",
    "    df[mapping[\"fecha_mov\"]]    = to_datetime_clean(df[mapping[\"fecha_mov\"]])\n",
    "    if mapping[\"monto_pagado\"]  is not None:\n",
    "        df[mapping[\"monto_pagado\"]]  = to_numeric_clean(df[mapping[\"monto_pagado\"]]).fillna(0.0)\n",
    "    if mapping[\"monto_reserva\"] is not None:\n",
    "        df[mapping[\"monto_reserva\"]] = to_numeric_clean(df[mapping[\"monto_reserva\"]]).fillna(0.0)\n",
    "    df = df.dropna(subset=[mapping[\"fecha_evento\"], mapping[\"fecha_mov\"]])\n",
    "    df = df[df[mapping[\"fecha_mov\"]] <= cutoff]\n",
    "\n",
    "    # >>>> AY FULL (TODOS los AY válidos hasta el corte) <<<<\n",
    "    df[\"__ay__\"] = df[mapping[\"fecha_evento\"]].apply(ay_end_year)\n",
    "    ay_full_sorted = sorted([int(x) for x in pd.unique(df[\"__ay__\"].dropna()) if x <= cutoff.year])\n",
    "\n",
    "    # Triángulos usando todos los AY (acumulación desde dev 0)\n",
    "    inc_paid_full, cum_paid_full = build_paid_triangle(\n",
    "        df, mapping[\"fecha_evento\"], mapping[\"fecha_mov\"], mapping[\"monto_pagado\"], ay_full_sorted, n_dev\n",
    "    )\n",
    "    tri_reserve_full = build_reserve_triangle(\n",
    "        df, mapping[\"fecha_evento\"], mapping[\"fecha_mov\"], mapping[\"monto_reserva\"], mapping[\"id_siniestro\"], ay_full_sorted, n_dev\n",
    "    )\n",
    "    tri_incurred_full = cum_paid_full.add(tri_reserve_full, fill_value=0.0)\n",
    "\n",
    "    # Mack sobre el triángulo completo (factores con toda la info disponible)\n",
    "    mack_all, cdf_df, params = mack_chain_ladder(tri_incurred_full)\n",
    "\n",
    "    # Al final, trabajamos solo con los últimos 5 AY (para reportar/resultados)\n",
    "    ay_last5 = ay_full_sorted[-5:] if keep_last5 else ay_full_sorted\n",
    "\n",
    "    # Subconjuntos para outputs finales\n",
    "    inc_paid_5     = inc_paid_full.loc[ay_last5]\n",
    "    cum_paid_5     = cum_paid_full.loc[ay_last5]\n",
    "    reserve_5      = tri_reserve_full.loc[ay_last5]\n",
    "    incurred_5     = tri_incurred_full.loc[ay_last5]\n",
    "    mack_by_ay_5   = mack_all.loc[ay_last5]\n",
    "    totals_5 = pd.DataFrame({\n",
    "        \"IBNR Total Mack\": [mack_by_ay_5[\"IBNR_Mack\"].sum()],\n",
    "        \"Ultimate Total Mack\": [mack_by_ay_5[\"Ultimate_Mack\"].sum()],\n",
    "        \"SE Total (aprox)\": [np.sqrt(np.nansum(np.square(mack_by_ay_5[\"SE_Mack\"])))]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"mapping\": mapping,\n",
    "        \"AY_full\": ay_full_sorted,\n",
    "        \"AY_last5\": ay_last5,\n",
    "        \"paid_incremental_full\": inc_paid_full,\n",
    "        \"paid_cumulative_full\": cum_paid_full,\n",
    "        \"reserve_full\": tri_reserve_full,\n",
    "        \"incurred_full\": tri_incurred_full,\n",
    "        \"mack_params\": params,\n",
    "        \"mack_cdf\": cdf_df,\n",
    "        \"mack_by_ay_full\": mack_all,\n",
    "        \"paid_incremental_last5\": inc_paid_5,\n",
    "        \"paid_cumulative_last5\": cum_paid_5,\n",
    "        \"reserve_last5\": reserve_5,\n",
    "        \"incurred_last5\": incurred_5,\n",
    "        \"mack_by_ay_last5\": mack_by_ay_5,\n",
    "        \"totals_last5\": totals_5\n",
    "    }\n",
    "\n",
    "# ==========================\n",
    "# CALCULO\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    out = run_pipeline(INPUT_PATH, CUTOFF, N_DEV, keep_last5=True)\n",
    "\n",
    "    pd.set_option('display.float_format', lambda x: f\"{x:,.2f}\" if isinstance(x, (int,float,np.floating)) else str(x))\n",
    "\n",
    "    print(\"\\nAY (todos hasta el corte):\", out[\"AY_full\"])\n",
    "    print(\"AY (últimos 5):\", out[\"AY_last5\"])\n",
    "\n",
    "    # Triángulos finales (últimos 5)\n",
    "    print(\"\\nPagados (incremental):\\n\",\n",
    "          out[\"paid_incremental_last5\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nPagados (acumulado):\\n\",\n",
    "          out[\"paid_cumulative_last5\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nReservas:\\n\",\n",
    "          out[\"reserve_last5\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nIncurridos:\\n\",\n",
    "          out[\"incurred_last5\"].rename_axis(index=None, columns=None).to_string())\n",
    "\n",
    "    # Mack (factores con todo el triángulo, resultados mostrados para últimos 5 AY)\n",
    "    print(\"\\nFactores acumulados (CDF):\\n\", out[\"mack_cdf\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nParámetros de Mack (f, sigma^2, S, n_pairs):\\n\",\n",
    "          out[\"mack_params\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nResultados Mack por AY:\\n\",\n",
    "          out[\"mack_by_ay_last5\"].rename_axis(index=None, columns=None).to_string())\n",
    "    print(\"\\nTotales:\\n\",\n",
    "          out[\"totals_last5\"].rename_axis(index=None, columns=None).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323f9f5-6be4-4a2b-ad3e-6157994c5a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
